{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "# from alphagen.config import *\n",
    "# from alphagen.data.tokens import *\n",
    "from alphagen.models.alpha_pool import AlphaPoolBase, AlphaPool\n",
    "from alphagen.rl.env.core import AlphaEnvCore\n",
    "import torch.nn.functional as F\n",
    "from gan.dataset import Collector\n",
    "from gan.network.generater import NetG_DCGAN\n",
    "from gan.network.masker import NetM\n",
    "from gan.network.predictor import NetP, train_regression_model,train_regression_model_with_weight\n",
    "from alphagen.rl.env.wrapper import SIZE_ACTION,action2token\n",
    "from alphagen_generic.features import open_\n",
    "from gan.utils import Builders\n",
    "from alphagen_generic.features import *\n",
    "from alphagen.data.expression import *\n",
    "from gan.utils.data import get_data_by_year\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "instruments: str = \"csi300\"\n",
    "from typing import Tuple\n",
    "import json\n",
    "\n",
    "def load_alpha_pool(raw) -> Tuple[List[Expression], List[float]]:\n",
    "    exprs_raw = raw['exprs']\n",
    "    exprs = [eval(expr_raw.replace('open', 'open_').replace('$', '')) for expr_raw in exprs_raw]\n",
    "    weights = raw['weights']\n",
    "    return exprs, weights\n",
    "\n",
    "def load_alpha_pool_by_path(path: str) -> Tuple[List[Expression], List[float]]:\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        raw = json.load(f)\n",
    "        return load_alpha_pool(raw)\n",
    "    \n",
    "import os\n",
    "def load_ppo_path(path,name_prefix):\n",
    "    \n",
    "    files = os.listdir(path)\n",
    "    folder = [i for i in files if name_prefix in i][-1]\n",
    "    names = [i for i in os.listdir(f\"{path}/{folder}\") if '.json' in i]\n",
    "    name = sorted(names,key = lambda x:int(x.split('_')[0]))[-1]\n",
    "    return f\"{path}/{folder}/{name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from alphagen_qlib.calculator import QLibStockDataCalculator\n",
    "freq = 'day'\n",
    "chk_path = \"out_ppo/checkpoints\"\n",
    "result = []\n",
    "for train_end in range(2016,2021):\n",
    "    returned = get_data_by_year(\n",
    "        train_start = 2010,train_end=train_end,valid_year=train_end+1,test_year =train_end+2,\n",
    "        instruments=instruments, target=target,freq='day',\n",
    "    )\n",
    "    data_all, data,data_valid,data_valid_withhead,data_test,data_test_withhead,name = returned\n",
    "    for seed in range(5):\n",
    "        for num in [1,10,20,50,100]:\n",
    "            name_prefix = f\"csi300_{train_end}_{num}_{seed}\"\n",
    "            path = load_ppo_path(chk_path,name_prefix)\n",
    "                \n",
    "            exprs,weights = load_alpha_pool_by_path(path)\n",
    "            \n",
    "            # calculator_test = QLibStockDataCalculator(data_test, target)\n",
    "            calculator_test = QLibStockDataCalculator(data_all, target)\n",
    "\n",
    "            ensemble_value = calculator_test.make_ensemble_alpha(exprs, weights)\n",
    "            ensemble_value = ensemble_value[-data_test.n_days:]\n",
    "            dirname = os.path.dirname(path)\n",
    "            \n",
    "            torch.save(ensemble_value.cpu(),f\"{dirname}/{train_end}_{num}_{seed}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the infer result and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from alphagen.utils.correlation import batch_pearsonr,batch_spearmanr\n",
    "device = 'cuda:0'\n",
    "result = []\n",
    "for seed in range(5):\n",
    "    cur_seed_ic = []\n",
    "    cur_seed_ric = []\n",
    "    \n",
    "    for num in [50,100]:\n",
    "        for train_end in range(2016,2021):\n",
    "            returned = get_data_by_year(\n",
    "                train_start = 2010,train_end=train_end,valid_year=train_end+1,test_year =train_end+2,\n",
    "                instruments=instruments, target=target,freq=freq,\n",
    "            )\n",
    "            data_all, data,data_valid,data_valid_withhead,data_test,data_test_withhead,name = returned\n",
    "\n",
    "            \n",
    "            name_prefix = f\"n1230day_csi500_{train_end}_{num}_{seed}\"\n",
    "            path = load_ppo_path(chk_path,name_prefix)\n",
    "            dirname = os.path.dirname(path)\n",
    "            pred = torch.load(f\"{dirname}/{train_end}_{num}_{seed}.pkl\").to(device)\n",
    "            tgt = target.evaluate(data_test)\n",
    "            tgt = target.evaluate(data_all)[-data_test.n_days:,:]\n",
    "\n",
    "            ic_s = torch.nan_to_num(batch_pearsonr(pred,tgt),nan=0)\n",
    "            rank_ic_s = torch.nan_to_num(batch_spearmanr(pred,tgt),nan=0)\n",
    "\n",
    "            cur_seed_ic.append(ic_s)\n",
    "            cur_seed_ric.append(rank_ic_s)\n",
    "        ic = torch.cat(cur_seed_ic)\n",
    "        rank_ic = torch.cat(cur_seed_ric)\n",
    "\n",
    "        ic_mean = ic.mean().item()\n",
    "        rank_ic_mean = rank_ic.mean().item()\n",
    "        ic_std = ic.std().item()\n",
    "        rank_ic_std = rank_ic.std().item()\n",
    "        tmp = dict(\n",
    "            seed = seed,\n",
    "            num = num,\n",
    "            ic = ic_mean,\n",
    "            ric = rank_ic_mean,\n",
    "            icir = ic_mean/ic_std,\n",
    "            ricir = rank_ic_mean/rank_ic_std,\n",
    "        )\n",
    "        result.append(tmp)\n",
    "\n",
    "import pandas as pd\n",
    "exp_result = pd.DataFrame(result).groupby(['num','seed']).mean().groupby('num').agg(['mean','std'])\n",
    "print(exp_result)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38n1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
